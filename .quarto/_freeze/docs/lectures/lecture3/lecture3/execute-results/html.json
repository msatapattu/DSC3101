{
  "hash": "2e877d9ed829a93d299ae857e02fdbfa",
  "result": {
    "markdown": "---\ntitle: DSC 3091- Advanced Statistics Applications I\nsubtitle: \"Point Estimation and Confidence Intervals\"\nauthor: Dr Jagath Senarathne\ninstitute: Department of Statistics and Computer Science \nformat: \n  revealjs:\n      theme: [serif, custom.scss]\n      slide-number: true\n      chalkboard: \n        theme: whiteboard\n      \neditor: visual\n---\n\n\n## Point Estimation\n\n**Recall**\n\n-   *Parameter*: Characteristics that are used to describe the population.\n\n-   *Statistic*: a function of the observable random variables in a sample which does not include any unknown quantities.\n\n-   *Estimator*: A statistic that is used to estimate an unknown parameter.\n\n## Point Estimation Cont...\n\n\\n\n\n| **Parameter**                  | **Estimator**               |\n|:-------------------------------|:----------------------------|\n| Population mean $\\mu$          | Sample mean $\\bar{x}$       |\n| Population variance $\\sigma^2$ | Sample variance $s^2$       |\n| Population proportion $p$      | Sample proportion $\\hat{p}$ |\n|                                |                             |\n\n## Maximum Likelihood Estimators\n\n-   The point in the parameter space that maximizes the likelihood function.\n\n-   Likelihood function is given by; $$ùêø(ùë•,\\theta)=\\prod_{ùëñ=1}^ùëõùëì(ùë•_i,\\theta)$$\n\n-   The idea of maximum likelihood estimation is to first assume our data come from a known family of distributions that contain parameters.\n\n-   Then the maximum likelihood estimates (MLEs) of the parameters will be the parameter values that are most likely to have generated our data.\n\n## Example 1\n\n-   Consider a simple coin-flipping example. Let's say we flipped a coin 200 times and observed 103 heads and 97 tails. If the probability of \"success\" (i.e. getting a head) is $p$,\n    1.  Define a function that will calculate the likelihood function for a given value of $p$; then\n\n    2.  Search for the value of $p$ that results in the highest likelihood.\n\n## Example 2\n\nSuppose we have data points representing the weight (in kg) of students in a class.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n [1] 59.001 38.267 41.025 35.555 46.690 20.994 39.407 52.780 57.495 52.416\n[11] 60.062 48.149 40.182 50.929 49.472 49.197 43.459 40.493 60.196 58.590\n[21] 53.645 53.837 61.134 62.115 46.517 41.404 56.500 53.281 44.821 47.610\n[31] 51.178 58.315 34.411 47.795 41.828 60.767 60.797 51.421 51.570 48.313\n[41] 47.310 58.078 38.753 35.692 50.604 42.070 53.403 47.405 36.952 53.682\n```\n:::\n:::\n\n\nThis dataset appears to follow a normal distribution. Find the MLEs for the mean and standard deviation for this distribution?\n\n------------------------------------------------------------------------\n\n#### Normal distribution - Maximum Likelihood Estimation\n\n-   The MLE of $\\mu$ is defined as $\\hat{\\mu}_{MLE}=argmax(x_1,...,x_n|\\mu,\\sigma^2)$; where $\\hat{\\mu}_{MLE}$ is the value of $\\mu$ that maximizes the likelihood function.\n\n![](images/paste-CAB44AE1.png){fig-align=\"center\" width=\"4471\"}\n\n-   If we maximise the above likelihood function, we get $\\hat{\\mu}_{MLE}=\\bar{x}.$\n\n-   Since the MLE of $\\mu$ is the sample mean, computing the MLE in R becomes straightforward.\n\n## Interval Estimation\n\n-   Point estimators are often use as sample measures for population parameters.\n\n-   It is also helpful to know how reliable this estimate is, that is, how much sampling uncertainty is associated with it.\n\n-   A useful way to express this uncertainty is to calculate an interval estimate or confidence interval for the population parameter\n\n-   In other words, the confidence interval is of the form \"**point estimate ¬± uncertainty**\"\n\n## \n\n### Confidence Interval for Mean\n\n**Case 1**: When data is normal/ large sample and $\\sigma$ is known.\n\n\n$$\\bar{x}\\pm z_{\\alpha/2}\\sigma/\\sqrt{n}$$\n\n\n![](images/paste-828890DC.png)\n\n------------------------------------------------------------------------\n\n**Case 2**: When data is normal/ large samples and $\\sigma$ is unknown.\n\n\n$$\\bar{x}\\pm t_{n-1,\\alpha/2}\\sigma/\\sqrt{n}$$\n\n\n![](images/paste-1B9E4230.png)\n\n------------------------------------------------------------------------\n\n**Case 3**: When data is non-normal/ small samples\n\n-   For this, bootstrap approach is used as follows.\n\n![](images/paste-E97242D1.png)\n\n------------------------------------------------------------------------\n\n### CONFIDENCE INTERVALS FOR Difference of Means\n\n**Case 1:** Sampling from two independent normal distributions with known variances.\n\n![](images/paste-EAF7E47A.png)\n\n![](images/paste-2363134F.png)\n\n    library(\"BSDA\")\n    z.test(x,y = NULL,alternative = \"two.sided\",\n    sigma.x = NULL, sigma.y = NULL, conf.level = 0.95)\n\n------------------------------------------------------------------------\n\n**Case 2:** Sampling from two independent normal distributions with unknown variances (small samples).\n\n-   when population variances are equal\n\n![](images/paste-20EC42F5.png)\n\n        t.test(x,y,alternative = \"two.sided\",\n        var.equal=TRUE, conf.level = 0.95)\n\n------------------------------------------------------------------------\n\n-   when population variances are unequal\n\n![](images/paste-AD18975E.png)\n\n![](images/paste-D5AF962F.png)\n\n      t.test(x,y,alternative = \"two.sided\",\n        var.equal=FALSE, conf.level = 0.95)\n\n------------------------------------------------------------------------\n\n### Confidence Interval Chart in R (Independent Means & CIs)\n\n![](https://www.researchgate.net/profile/Sarah-Vanhoutte/publication/294318520/figure/fig16/AS:614068499009558@1523416747796/Graph-depicting-the-95-confidence-interval-of-the-CNV-slope-for-all-electrodes-of.png)\n\n------------------------------------------------------------------------\n\n-   Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123456)                 # Create example data\ndata <- data.frame(x = c(\"A\",\"B\",\"C\"),\n                  y = round(runif(3, 10, 20),2),\n                  lower = round(runif(3, 0, 10),2),\n                  upper = round(runif(3, 20, 30),2))\n\nlibrary(ggplot2)\nggplot(data, aes(x, y)) +        # ggplot2 plot with confidence intervals\n  geom_point() +\n  geom_errorbar(aes(ymin = lower, ymax = upper))\n```\n\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Confidence Intervals for Proportion\n\n-   **Case 1**: For large sample (Using Normal approximation)\n\n\n$$ \\hat{p}\\pm Z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n\n\n![](images/paste-7C863FC6.png)\n\n------------------------------------------------------------------------\n\n**Case 1**: For large sample (Using Binomial Distribution)\n\n-   we can use the following functions from R package *epitools* for this case.\n\n![](images/paste-A89B3710.png)\n\n------------------------------------------------------------------------\n\n**Case 2**: For small sample (Using Binomial Distribution)\n\n-   When sample size is small, confidence interval for population can be calculated using binom.test() function.\n\n![](images/paste-74B0E647.png)\n\n------------------------------------------------------------------------\n\n### Confidence Intervals for Variance\n\n**Case 1**: Under normality assumption\n\n-   User defined function to obtain confidence interval for variance.\n\n<!-- -->\n\n     var.interval = function(data, conf.level = 0.95) {\n     df = length(data) - 1\n     chilower = qchisq((1 - conf.level)/2, df)\n     chiupper = qchisq((1 - conf.level)/2, df, lower.tail = FALSE)\n     v = var(data)\n     c(df * v/chiupper, df * v/chilower)\n     }\n     \n     lizard = c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5, 8.6, 8.8, 8.8, 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8, 11.3, 11.9)\n\n     var.interval(lizard)\n\n------------------------------------------------------------------------\n\n**Case 2**: Under non-normality assumption\n\n-   When no assumption is made about data, a bootstrap method is used to obtain confidence intervals for the population variance.\n\n![](images/paste-41E6DA37.png)\n",
    "supporting": [
      "lecture3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}