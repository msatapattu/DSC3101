{"title":"DSC 3091- Advanced Statistics Applications I","markdown":{"yaml":{"title":"DSC 3091- Advanced Statistics Applications I","subtitle":"Hypothesis Testing","author":"Dr Jagath Senarathne","institute":"Department of Statistics and Computer Science","format":{"revealjs":{"theme":["beige","custom.scss"],"slide-number":true,"chalkboard":{"theme":"whiteboard"}}},"editor":"visual"},"headingText":"Hypothesis Testing","containsRefs":false,"markdown":"\n\n\n-   Statistical hypothesis is an assumption or a statement\\\n    which may or may not be true concerning one or more populations.\\\n\n    ![](images/Hypothesis.png){fig-aligh=\"center\"}\n\n------------------------------------------------------------------------\n\n-   The purpose of hypothesis testing is to choose between two conflicting hypotheses about the value of a population parameter.\n\n-   A hypothesis test involves two hypothesis:\n\n    -   Null hypothesis (H0) : a statement to be tested (the case of \"no effect\" or \"no change\").\n\n    -   The alternative hypothesis (HA): a statement that is an alternative to the null hypothesis.\n\n-   The hypothesis test is aimed to test if the null hypothesis should be rejected in favor of the alternative hypothesis.\n\n-   The criterion for deciding whether to reject the null hypothesis involves a so-called test statistic.\n\n## One Sample Test for Mean: when population variance is known.\n\n![](images/OneSampleTest.PNG){fig-align=\"center\"}\n\n## Z-test\n\nHypothesis:\n\n$H_{0}:\\;\\mu=\\mu_{0}\\;{\\text{vs.}\\;}H_{1}:\\:\\mu\\neq\\mu_{0}$ or\n\n$H_{0}:\\;\\mu\\leq\\mu_{0}\\;{\\text{vs.}\\;}H_{1}:\\:\\mu>\\mu_{0}$ or\n\n$H_{0}:\\;\\mu\\geq\\mu_{0}\\;{\\text{vs.}\\;}H_{1}:\\:\\mu<\\mu_{0}$\n\nTest statistic:\n\n$Z=\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}\\sim N(0,\\,1)$\n\n## Example\n\nA factory makes tins of soy beans. The desired average weight of a tin is 160g and the weights follows a normal distribution with variance of 15g. Using a sample of 20 cans, let's statistically test whether the population weight of the tins meets the expectations.\n\n```{r, eval=FALSE, echo=T}\nweights=c(165.1,171.5,168.1,165.6,166.8,170.0,168.8,171.1,168.8,173.6,163.5,169.9,165.4,174.4,171.8,166.0,174.6,174.5,166.4,173.8)\n\nlibrary(\"BSDA\")\nz.test(x=weights, mu = 160,sigma.x =15, alternative = \"two.sided\")\n\n```\n\n## One Sample Test for mean: when population variance is unknown\n\n![](images/OneSampleTest_UnKV.PNG){fig-align=\"center\"}\n\n## Example\n\nA factory makes tins of soy beans. The desired average weight of a tin is 160g and the weights follows a normal distribution. Using a sample of 20 cans, let's statistically test whether the population weight of the tins meets the expectations.\n\n```{r, eval=FALSE,echo=TRUE}\nweights <- c(165.1,171.5,168.1,165.6,166.8,170.0,168.8,171.1,168.8,173.6,163.5,169.9,165.4,174.4,171.8,166.0,174.6,174.5,166.4,173.8)\nt.test(weights, mu = 160, alternative = \"two.sided\")\n```\n\nNote that according to the test we could use \"two.sided\", \"less\" and \"greater\" for the alternative argument.\n\n------------------------------------------------------------------------\n\n## One Sample Proportion Test\n\n$p=\\frac{\\# \\; of \\; success}{\\# \\; of \\; trials}$\n\nHypothesis:\n\n$H_{0}:\\;p=p_{0}\\;{\\text{vs.}\\;}H_{1}:\\:p\\neq p_{0}$ or\n\n$H_{0}:\\;p\\leq p_{0}\\;{\\text{vs.}\\;}H_{1}:\\:p>p_{0}$ or \\n $H_{0}:\\;p\\geq p_{0}\\;{\\text{vs.}\\;}H_{1}:\\:p<p_{0}$ \\n\n\n**Case I: Large sample**\n\nTest statistic:\n\n$Z=\\frac{\\hat{p}-p_0}{\\sqrt{p_0(1-p_0)/n}}\\sim N(0,\\,1)$\n\n## Check the assumptions for Proportion Test\n\n-   A simple random sample of size n is taken.\n\n-   The conditions for the binomial distribution are satisfied.\n\n-   To determine the sampling distribution of $\\hat{p}$, we need to show that $np \\geq 5$ and $nq \\geq 5$,\n\nwhere $q=1-p$. If this requirement is true, then the sampling distribution of $\\hat{p}$ is well approximated by a normal curve.\n\n## Example\n\nThe following variable shows the hair colour of 3000 people. Using a sample of 1000 people we are going to check whether the proportion of black hair is equal to 0.5.\n\n```{r, eval=FALSE,echo=TRUE}\nset.seed(10)\n Hair_col <- c(rep(\"black\", 1500), rep(\"brown\", 1000), rep(\"blonde\", 500))\n sampleP <- sample(Hair_col,1000)\n Ptable <-table(sampleP) \t\t \n prop.test(x = 498, n= 1000, p=0.5, alternative = \"two.sided\", conf.level = 0.95, correct = FALSE)\n\n```\n\n## Case II: Small Samples\n\n-   In that case, the function binom.test() can be used for an exact calculation based on the binomial distribution\n\nExample: In the previous example, suppose we take a sample of 10.\n\n```{r, eval=FALSE,echo=TRUE}\nset.seed(10)\nsampleS<- sample(Hair_col,10)\nStable <- table(sampleS)\nStable\n\nbinom.test(x= 3, n=10, p=0.5, alternative = \"two.sided\" )\t\n```\n\n## Hypothesis Testing for Variance : One Sample\n\n-   Let $X$ be a random variable with variance $\\sigma^2$ and sample of size $n$\n\n-   The hypotheses of the test are,\n\n    ![](images/paste-3BCC02CC.png){width=\"532\"}\n\n-   Under $H_0$, Test statistic is,\n\n    ![](images/paste-C0315F4C.png){width=\"351\"}\n\n-   This test is valid only for normally distributed data.\n\n## Example:\n\nLet's recall the example of manufacturing cans of soy beans and check whether the variance of the population is 10.\n\n```{r, eval=FALSE,echo=TRUE}\nweights <- c(165.1,171.5,168.1,165.6,166.8,170.0,168.8,\n             171.1,168.8,173.6,163.5,169.9,165.4,174.4,\n             171.8,166.0,174.6,174.5,166.4,173.8)\n\nlibrary(EnvStats)\nvarTest(weights, sigma =10, alternative = \"two.sided\")\n```\n\n## Two sample test for Means\n\n**Case I**: equal Variances\n\n-   The hypotheses of the test are,\n\n    ![](images/paste-9D118A76.png){width=\"377\"}\n\n-   Under $H_0$, Test statistic is,\n\n    ![](images/paste-90BDE5EE.png){width=\"551\"}\n\n![](images/paste-4EC07F99.png){width=\"444\"}\n\n## Example\n\nBody fat percentages of 13 males and 10 females are given in the following variables. We need to check whether body fat percentage of males differs from that of females. Note that the body fat percentages follows a normal distribution.\n\nTo check whether the variances are equal, we should use a two sample variance test first, but for this example, let's suppose variances are equal.\n\n```{r, eval=FALSE, echo=TRUE}\nfat_m <- c(13.3,6.0,20.0,8.0,14.0,19.0,18.0,25.0,16.0,24.0,15.0,1.0,15.0)\nfat_w <- c(22.0,16.0,21.7,21.0,30.0,26.0,12.0,23.2,28.0,23.0)\n\nt.test(fat_w,fat_m, var.equal = TRUE)\n\n\n```\n\n## Case II: Unequal Variances\n\n-   Test statistic:\n\n${T= \\frac{\\overline{x}_1-\\overline{x}_2}{\\sqrt{\\frac{s^2_1}{n_1}+\\frac{s^{2}_2}{n_2}}}}\\sim t(a)$ \\vspace{0.3 cm}\n\nwhere\n\n\\hspace{3 cm}\n\n$a=\\frac{\\Big({\\frac{s^2_1}{n_1}+\\frac{s^{2}_2}{n_2}}\\Big)^2}{\\frac{({s^2_1}/{n_1})^2}{n_1-1}+\\frac{({s^2_2}/{n_2})}{n_2-1}}$\n\n-   This test is valid for normally distributed variables $X_1$ and $X_2$ with unequal variance.\n\n## Example\n\nLet's recall the previous body fat percentage example and let's assume that the variances are not equal.\n\n```{r, eval=FALSE, echo=TRUE}\nfat_m <- c(13.3,6.0,20.0,8.0,14.0,19.0,18.0,25.0,16.0,24.0,15.0,1.0,15.0)\nfat_w <- c(22.0,16.0,21.7,21.0,30.0,26.0,12.0,23.2,28.0,23.0)\n\nt.test(fat_w,fat_m, var.equal = FALSE)\n\n```\n\n## Hypothesis Testing for Mean : Paired Samples\n\n-   The hypotheses of the test are,\n\n    ![](images/paste-D44D2BBD.png)\n\n-   Under $H_0$, Test statistic is,\n\n    ![](images/paste-7BA5E5FD.png)\n\n-   This test is valid only for normally distributed data or large samples (n \\> 30).\n\n## Example\n\nSoil samples that were taken from 15 locations were divided in half and sent to two laboratories to test. The measurements that were observed are given in the following variables.\n\n```{r, eval=FALSE,echo=TRUE}\nlab1 <- c(22,18,28,26,13,8,21,26,27,29,25,24,22,28,15)\nlab2 <- c(25,21,31,27,11,10,25,26,29,28,26,23,22,25,17)\n\n```\n\nWe want to check whether the two laboratories give the same result.\n\n```{r, eval=FALSE,echo=TRUE}\nt.test(lab1,lab2, paired = TRUE)\n\n```\n\n## Hypothesis Testing for Proportion : Two Samples\n\n-   The hypotheses of the test are,\n\n    ![](images/paste-30B37F8A.png)\n\n-   Under $H_0$, Test statistic is,\n\n    ![](images/paste-03464F77.png)\n\n-   To use this test, the sample must be large enough.\n\n```{r,echo=T, eval=F}\nprop.test(x = c(490, 400), n = c(500, 500))\n```\n\n## Hypothesis Testing for Variance : Two Samples\n\n-   The hypotheses of the test are,\n\n    ![](images/paste-B68D9AC0.png)\n\n-   Under $H_0$, Test statistic is,\n\n    ![](images/paste-E17FFA93.png)\n\n-   This test is valid only for normally distributed samples.\n\n## Example\n\nRecall the body fat percentage example of male and female. Previously we assumed that the variances are not equal. We can actually check whether the variances are equal or not. \\n\n\n```{r, eval=FALSE, echo=TRUE}\nfat_m <- c(\t13.3,6.0,20.0,8.0,14.0,19.0,18.0,25.0,16.0,24.0,15.0,1.0,15.0)\nfat_w <- c(22.0,16.0,21.7,21.0,30.0,26.0,12.0,23.2,28.0,23.0)\n\nvar.test(fat_m, fat_w)\n\n```\n\n## Check the Normality assumption\n\n-   Shapiro-Wilk test\n\n```{r, eval=FALSE, echo=TRUE}\nshapiro.test(my_data)\n```\n\n-   Anderson-Darling test\n\n```{r, eval=FALSE, echo=TRUE}\ninstall.packages('nortest')\nlibrary(nortest)\nad.test(my_data)\n```\n\n-   Kolmogorov-Smirnov test\n\n```{r, eval=FALSE, echo=TRUE}\nks.test(my_data, \"pnorm\")\n```\n\n## Non- Parametric Tests\n\n-   Non-parametric tests are distribution free.\n\n-   The only assumption holds for these tests is that the data should be an independent random sample.\n\n-   Examples:\n\n    Tests on position- Sign test and Wilcoxon sign rank test\n\n## Sign Test\n\nCase I: One sample\n\n-   In this test we wish to compare the true median of a sample with a theoretical value.\n\n    ![](images/paste-4AA0C775.png){width=\"312\"}\n\n-   Test statistic:\n\n    Two sided test : $\\max(k^+,k^-)$, right sided test: $k^+$ and left sided test: $k^-$,\n\nwhere $k^+$ is the number of values strictly greater than $\\eta_0$ and $k^-$ is the number of values strictly lower than $\\eta_0$.\n\n## Example\n\nThe median price of one-bedroom flats in New York in 2008 was 130,000 dollars. We are given a sample of 32 flats (in 1000 dollars) in 2009 and we need to check whether the prices are rising than in 2008.\n\n```{r, echo=T, eval=F}\nm0 <- 130 # median in 2008\nprices <- c(230.00,148.00,126.00,134.62,155.00,157.70,\n            160.00,225.00,125.00,109.00,157.00,115.00,\n            125.00,225.00,118.00,179.00,176.00,125.00,\n            123.00,180.00,151.00,120.00,143.00,170.00,\n            190.00,233.00,148.72,189.00,121.00,149.00,\n            225.00,240.00)\n\nlibrary(BSDA)\nSIGN.test(prices,md = m0, alternative=\"greater\")\n\n```\n\n## Case II: Sign Test for Two Paired Samples\n\n-   In this test we wish to compare the true median of two Paired samples\n\n    ![](images/paste-D0DC6E86.png){width=\"429\"}\n\n-   Test statistic:\n\n    Two sided test : $\\max(k^+,k^-)$, right sided test: $k^+$ and left sided test: $k^-$,\n\nwhere $k^+$ is the number of values strictly greater than $\\eta_1-\\eta_2$ and $k^-$ is the number of values strictly lower than $\\eta_1-\\eta_2$.\n\n## Example\n\nSoil samples that were taken from 15 locations were divided in half and sent to two laboratories to test. The measurements that were observed are given in the following variables. Note that no assumptions are made.\n\n```{r, echo=T, eval=F}\nlab1 <- c(22,18,28,26,13,8,21,26,27,29,25,24,22,28,15)\nlab2 <- c(25,21,31,27,11,10,25,26,29,28,26,23,22,25,17)\n\nlibrary(BSDA)\nSIGN.test(x = lab1,\n          y = lab2,\n          alternative = \"two.sided\",\n          conf.level = 0.95)\n\n```\n\n## Wilcoxon Sign Rank Test\n\nCase I: One Sample Sign Rank Test\n\n-   This is an alternative test for sign test which uses not only the sign but also the rank difference into account.\n\n    ![](images/paste-986284A4.png){width=\"312\"}\n\n-   Test statistic:\n\n    Two sided test : $\\min(\\tau^+,\\tau^-)$, right sided test: $\\tau^+$ and left sided test: $\\tau^-$,\n\nwhere $\\tau^+$ and $\\tau^-$ are the sum of ranks of positive and negative differences from $\\eta_0$.\n\n## Example\n\nLet's apply the Wilcoxon sign rank test for the same flat prices example considered in sign test.\n\n```{r,eval=FALSE,echo=TRUE,}\nm0 <- 130 # median in 2008\nprices <- c(230.00,148.00,126.00,134.62,155.00,157.70,\n            160.00,225.00,125.00,109.00,157.00,115.00,\n            125.00,225.00,118.00,179.00,176.00,125.00,\n            123.00,180.00,151.00,120.00,143.00,170.00,\n            190.00,233.00,148.72,189.00,121.00,149.00,\n            225.00,240.00)\n\nwilcox.test(prices,m0, exact = FALSE, alternative = \"greater\")\n\n```\n\n## Case II: Sign Rank Test for Two Paired Samples\n\n-   The hypotheses for this test are;\n\n    ![](images/paste-1C1C99C1.png){width=\"428\"}\n\n-   Test statistic:\n\n    Two sided test : $\\min(\\tau^+,\\tau^-)$, right sided test: $\\tau^+$ and left sided test: $\\tau^-$,\n\nwhere $\\tau^+$ and $\\tau^-$ are the sum of ranks of positive and negative differences from $\\eta_1-\\eta_2$.\n\n## Example\n\nRecall the soil sample example we used for paired sign test and let's use Wilcoxon sign rank test for paired samples to compare the medians.\n\n```{r,echo=T,eval=F}\nlab1 <- c(22,18,28,26,13,8,21,26,27,29,25,24,22,28,15)\nlab2 <- c(25,21,31,27,11,10,25,26,29,28,26,23,22,25,17)\n\nwilcox.test(lab1, lab2, paired = TRUE, exact = FALSE)\n\n\n```\n\n## Case III: Sign Rank Test for Two independent Samples\n\n![](images/paste-3E9711E3.png){width=\"163\"}\n\n**Example:**\n\nBody fat percentages of 10 males and females are given in the following variables. We need to check whether median body fat percentage of males differs from that of females.\n\n```{r,echo=T,eval=F}\nfat_m <- c(\t13.3,6.0,20.0,8.0,14.0,19.0,18.0,25.0,16.0,24.0)\nfat_w <- c(22.0,16.0,21.7,21.0,30.0,26.0,12.0,23.2,28.0,23.0)\nwilcox.test(fat_m, fat_w, alternative = \"two.sided\")\n\n```\n\n# Some Useful Links ...\n\n-   <https://www.youtube.com/watch?v=VK-rnA3-41c>\n\n-   <https://rcompanion.org/handbook/>\n\n-   <https://data-flair.training/blogs/hypothesis-testing-in-r/>\n\n-   <http://www.r-tutor.com/elementary-statistics/hypothesis-testing>\n\n-   <https://www.analyticsvidhya.com/blog/2021/07/hypothesis-testing-made-easy-for-the-data-science-beginners/>\n\n-   [https://towardsdatascience.com/hypothesis-testing-for-data-scientists-everything-you-need-to-know-8c36ddde4cd2#](https://towardsdatascience.com/hypothesis-testing-for-data-scientists-everything-you-need-to-know-8c36ddde4cd2#:~:text=Hypothesis%20testing%20is%20a%20common,given%20a%20random%20data%20sample)\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["../lectures.css"],"output-file":"lecture4.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.0.38","auto-stretch":true,"editor":"visual","sidebar":"lectures","search":false,"title":"DSC 3091- Advanced Statistics Applications I","subtitle":"Hypothesis Testing","author":"Dr Jagath Senarathne","institute":"Department of Statistics and Computer Science","theme":["beige","custom.scss"],"slideNumber":true,"chalkboard":{"theme":"whiteboard"}}}}}