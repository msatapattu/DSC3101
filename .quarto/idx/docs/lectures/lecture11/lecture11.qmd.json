{"title":"DSC 3091- Advanced Statistics Applications I","markdown":{"yaml":{"title":"DSC 3091- Advanced Statistics Applications I","subtitle":"Web Scraping using R","author":"Prof. P. Wijekoon","institute":"Department of Statistics and Computer Science","format":{"revealjs":{"large":true,"theme":["beige","custom.scss"],"slide-number":true,"chalkboard":{"theme":"whiteboard"}}},"editor":"visual"},"headingText":"**Accessing Data from Websites**","containsRefs":false,"markdown":"\n\n\n-   Data Scientists need the skill to get the right data for the problem that they want to solve.\n\n-   In many practical situations, an already prepared database may not exist, and they may have to pull data from the right sources.\n\n-   For this purpose, Web Scraping and APIs are used.\n\n# **Web Scraping**\n\n-   Although many websites contain some important data, the users cannot download them directly.\n\n-   Most of these websites don't provide APIs, and one way to get this data is to manually copy and paste, which is a tedious and time-consuming method.\n\n-   Instead, web-scraping can be done, which is an automatic process of data extraction from websites.\n\n-   Using web-scraping one can convert the data that present in unstructured format (HTML tags) over the web to the structured format which can easily be accessed and used.\n\n# **Web Scraping**\n\n-   Web Scraping is done with the help of software called web scrapers.\n\n-   They automatically load and extract data from the websites based on user requirements.\n\n-   A web page may have text, images, links etc., and the main languages used to build web pages are called Hypertext Markup Language (HTML), Cascasing Style Sheets (CSS) and Javascript.\n\n# **Web Scraping**\n\n-   A knowledge of HTML and CSS will be an added advantage for web-scraping.\n\n-   To view the underline codes on a web page in Chrome, simply click Ctrl+Shift+C (or F12) in Windows which opens up the Elements console.\n\n# **Web Scraping**\n\n-   However, if you don't have the technical knowledge of HTML and CSS, install the [Chrome Extension](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb) of Selector Gadget (https://selectorgadget.com/) software.\n\n-   Using this Chrome extension, you can select the necessary HTML and CSS tags to perform Web scraping\n\n# Example\n\nThe 100 most popular feature films released in 2016 are given in IMDb website (https://www.imdb.com/search/title/?count=100&release_date=2016,2016&title_type=feature). To scrape the data in this site, we use the commonly used web Scraping package in R, i.e. **rvest**, which is one of the `tidyverse` packages introduced by Hadley Wickham.\n\n```{r echo=T}\nlibrary('rvest')\n#Read HTML code of the website\nwebpage = read_html(\"http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature\")\n\n```\n\nFirst, we scrape the **rank** of the film which are given from 1 to 100 as in 2016 list.\n\n------------------------------------------------------------------------\n\nClick the selector gadget Chrome extension, and then click the rankings field. Then, copy the corresponding CSS selector shown in box at the bottom. In this case, it is `.text-primary`. ![](plot1.png)\n\n------------------------------------------------------------------------\n\nNow, we use this CSS selector to get all the rankings as below:\n\n```{r echo=T}\nrank <- html_nodes(webpage,'.text-primary')\n#Convert the ranks to text\nrank_dat <- html_text(rank)\nhead(rank_dat)\n# Convert data to nemeric\nrank_dat <-as.numeric(rank_dat)\nhead(rank_dat)\n```\n\nTry to scrape the title, description, runtime, genre, IMDb ratings, votes, director, and actor of the films.\n\n------------------------------------------------------------------------\n\n## Scraping the title\n\n```{r echo=T}\ntitle <- html_nodes(webpage,'.lister-item-header a')\ntitle_dat <- html_text(title)\ntitle_dat <-as.factor(title_dat)\nhead(title_dat)\n```\n\n------------------------------------------------------------------------\n\n## Scraping the description\n\n```{r echo=T}\ndecs <- html_nodes(webpage,'.ratings-bar+ .text-muted')\ndecs_dat <- html_text(decs)\nhead(decs_dat)\n#removing \\n\ndecs_dat<-gsub(\"\\n\",\"\",decs_dat)\ndecs_dat <-as.factor(decs_dat)\nhead(decs_dat)\n```\n\n------------------------------------------------------------------------\n\n## Scraping the runtime\n\n```{r echo=T}\nrunt <- html_nodes(webpage,'.runtime')\nrunt_dat <- html_text(runt)\nhead(runt_dat)\n#Remove min from data\nrunt_dat<-gsub(\" min\",\"\",runt_dat)\nrunt_dat <-as.numeric(runt_dat)\nhead(runt_dat)\n```\n\n------------------------------------------------------------------------\n\n## Scraping the genre\n\n```{r echo=T}\ngenr <- html_nodes(webpage,'.genre')\ngenr_dat <- html_text(genr)\nhead(genr_dat)\n#removing \\n\ngenr_dat<-gsub(\"\\n\",\"\",genr_dat)\n#removing excess spaces\ngenr_dat<-gsub(\" \",\"\",genr_dat)\n#taking only the first genre of each movie\ngenr_dat<-gsub(\",.*\",\"\",genr_dat)\ngenr_dat <-as.factor(genr_dat)\nhead(genr_dat)\n```\n\n------------------------------------------------------------------------\n\n## Scraping the Ratings\n\n```{r echo=T}\nrate <- html_nodes(webpage,'.ratings-imdb-rating strong')\nrate_dat <- html_text(rate)\nrate_dat <-as.numeric(rate_dat)\nhead(rate_dat)\n```\n\n------------------------------------------------------------------------\n\n## Scraping the votes of each films\n\n```{r echo=T}\nvote <- html_nodes(webpage,'.sort-num_votes-visible span:nth-child(2)')\nvote_dat <- html_text(vote)\nhead(vote_dat)\n#remove commas and convert to numeric\nvote_dat<-gsub(\",\",\"\",vote_dat)\nvote_dat<- as.numeric(vote_dat)\nhead(vote_dat)\n```\n\n------------------------------------------------------------------------\n\n## Scraping the director of each film\n\n```{r echo=T}\ndirec <- html_nodes(webpage,'.text-muted+ p a:nth-child(1)')\ndirec_dat <- html_text(direc)\ndirec_dat <-as.factor(direc_dat)\nhead(direc_dat)\n\n```\n\n------------------------------------------------------------------------\n\n## Scraping the actors of each film\n\n```{r echo=T}\nact <- html_nodes(webpage,'.lister-item-content .ghost+ a')\nact_dat <- html_text(act)\nact_dat <-as.factor(act_dat)\nhead(act_dat)\n```\n\n------------------------------------------------------------------------\n\n## Combine all variables and create a data.frame\n\n```{r echo=T}\nfilms<-data.frame(Rank = rank_dat, Title = title_dat,Description = decs_dat, Runtime = runt_dat,Genre = genr_dat, Rating = rate_dat,\nVotes = vote_dat, Director = direc_dat, Actor = act_dat)\nstr(films)\n\n```\n\n# Visualizing Data\n\n-   Draw a histogram to show the **Runtime** according to the variable **Genre** using `ggplot2`.\n\n-   Draw a scatter plot to identify the Genre having the longest runtime.\n\n-   Draw a scatter plot to identify the genre which has the highest votes within the Runtime of 130-160 mins.\n\n------------------------------------------------------------------------\n\nDraw a histogram to show the **Runtime** according to the variable **Genre** using `ggplot2`.\n\n```{r echo=T}\nlibrary(ggplot2)\nqplot(data = films,Runtime,fill = Genre,bins = 35)\n```\n\n------------------------------------------------------------------------\n\nDraw a scatter plot to identify the Genre having the longest runtime.\n\n```{r echo=T}\nlibrary(dplyr)\nfilms %>%\n  ggplot(aes(x=Runtime,y=Rating))+\n  geom_point(aes(size=Votes,col=Genre))\n```\n\n------------------------------------------------------------------------\n\nDraw a scatter plot to identify the genre which has the highest votes within the Runtime of 130-160 mins.\n\n```{r echo=T}\nlibrary(dplyr)\nfilms %>%\n  ggplot(aes(x=Runtime,y=Votes))+\n  geom_point(aes(size=Rating,col=Genre))\n```\n\n# **API (Application Program Interface)**\n\n-   An API is a set of methods and tools that allows to query and retrieve data dynamically.\n\n-   Some companies provide free APIs to access the information they stored in their servers.\n\n-   For example, Twitter, Facebook, Reddit, Spotify provide free APIs.\n\n# Example with API\n\nHere we use API of IMDB website (https://www.omdbapi.com/). First, sign up for an API key.\n\n![](plot2.png)\n\n------------------------------------------------------------------------\n\nThen, you will get an API key to your email, and activate it.\n\nClick on the API key. Then you find some information related to one movie which is a **JSON** formatted entry. To work with this format, install `RJSONIO` R package. You can access the data related to that movie by using the following codes with your API key.\n\n```{r echo=T}\nlibrary(RJSONIO)\nmovie1 <- fromJSON(\"http://www.omdbapi.com/?apikey=f7c004c&t=The+Godfather\")\nstr(movie1)\n\n```\n\n------------------------------------------------------------------------\n\nChange the name of the movie, and get the relevant information.\n\n```{r echo=T}\nlibrary(RJSONIO)\nmovie2 <- fromJSON(\"http://www.omdbapi.com/?apikey=f7c004c&t=Suspiria\")\nstr(movie2)\n```\n\n------------------------------------------------------------------------\n\nTo get information easily from IMDB website, there is a new package called `omdbapi`, which can be downloaded from github as below:\\\n`devtools::install_github(\"hrbrmstr/omdbapi\")`\n\nThe functions related to this R package is given below:\n\n::: columns\n::: {.column width=\"50%\"}\n-   `find_by_id`: To search IMDB ID\n\n-   `find_by_title`: OMDB movie title search\n\n-   `get_actors`: Get actors from an omdb movie\n\n-   `get_countries`: Get countries from an omdb object\n:::\n\n::: {.column width=\"50%\"}\n-   `get_directors`: Get directors from an omdb object\n\n-   `get_genres`: Get genres from an omdb object\n\n-   `get_writers`: Get writers from an omdb object\n\n-   `search_by_title`: Lightweight OMDB title search\n:::\n:::\n\n------------------------------------------------------------------------\n\nFind other details from here: https://github.com/hrbrmstr/omdbapi\n\nFor example, if you need to get the information related to Captain America use the following codes, and provide your API key when prompted.\n\n```{r echo=T}\nlibrary(omdbapi)\nlibrary(tidyverse)\nsearch_by_title(\"Captain America\")\n```\n\n# Working with Twitter API\n\nA tutorial for getting APi from Twitter is given in this tutorial: https://cran.r-project.org/web/packages/rtweet/vignettes/auth.html\n\nYou have to install the `rtweet` and `tidytext` R packages to work with Twitter.\n\nMany websites offer API. A big list can be found here: https://www.programmableweb.com/\n\n# Class work\n\n-   The web site [NY Times Best Sellers: Hardcover Fiction](http://www.nytimes.com/books/best-sellers/hardcover-fiction) contains a list of best-selling fiction books. Scrape the names of these top books. The list of books are tagged via `<h2>title</h2>`.\n\n-   Refer the tutorial https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/ , and work with Twitter data.\n\n# More Details\n\n-   Web Scraping: https://www.scrapingbee.com/blog/\n\n-   Web Scraping with R: https://steviep42.github.io/webscraping/book/\n\n-   Web Scraping in R: https://www.scraperapi.com/blog/web-scraping-with-r/\n\n-   Introduction to Data scraping with R : https://stat2labs.sites.grinnell.edu/Handouts/rtutorials/IntroDataScraping.html\n\n-   Facebook API: https://elfsight.com/blog/2020/10/how-to-get-and-use-facebook-api/\n\n------------------------------------------------------------------------\n\n-   The twitter API in R : https://dgarcia-eu.github.io/SocialDataScience/2_SocialDynamics/027_rtweet/rtweet.html\n\n-   Pulling tweets in to R: https://towardsdatascience.com/pulling-tweets-into-r-e17d4981cfe2\n\n-   EarthLab Twitter data: https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/\n\n-   Accessing weather data: https://github.com/hrbrmstr/weatherkit\n\n-   https://rpubs.com/jaketelliott/scraping-tutorial\n\n-   Boehmke, Bradley. *Scraping Data*. Retrieved from <https://afit-r.github.io/scraping>\n\n-   https://rpubs.com/nabiilahardini/itchio\n\n-   \n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["../lectures.css"],"output-file":"lecture11.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.0.38","auto-stretch":true,"editor":"visual","sidebar":"lectures","search":false,"title":"DSC 3091- Advanced Statistics Applications I","subtitle":"Web Scraping using R","author":"Prof. P. Wijekoon","institute":"Department of Statistics and Computer Science","large":true,"theme":["beige","custom.scss"],"slideNumber":true,"chalkboard":{"theme":"whiteboard"}}}}}