{"title":"DSC 3091- Advanced Statistics Applications I","markdown":{"yaml":{"title":"DSC 3091- Advanced Statistics Applications I","subtitle":"Point Estimation and Confidence Intervals","author":"Dr Jagath Senarathne","institute":"Department of Statistics and Computer Science","format":{"revealjs":{"theme":["serif","custom.scss"],"slide-number":true,"chalkboard":{"theme":"whiteboard"}}},"editor":"visual"},"headingText":"Point Estimation","containsRefs":false,"markdown":"\n\n\n**Recall**\n\n-   *Parameter*: Characteristics that are used to describe the population.\n\n-   *Statistic*: a function of the observable random variables in a sample which does not include any unknown quantities.\n\n-   *Estimator*: A statistic that is used to estimate an unknown parameter.\n\n## Point Estimation Cont...\n\n\\n\n\n| **Parameter**                  | **Estimator**               |\n|:-------------------------------|:----------------------------|\n| Population mean $\\mu$          | Sample mean $\\bar{x}$       |\n| Population variance $\\sigma^2$ | Sample variance $s^2$       |\n| Population proportion $p$      | Sample proportion $\\hat{p}$ |\n|                                |                             |\n\n## Maximum Likelihood Estimators\n\n-   The point in the parameter space that maximizes the likelihood function.\n\n-   Likelihood function is given by; $$ùêø(ùë•,\\theta)=\\prod_{ùëñ=1}^ùëõùëì(ùë•_i,\\theta)$$\n\n-   The idea of maximum likelihood estimation is to first assume our data come from a known family of distributions that contain parameters.\n\n-   Then the maximum likelihood estimates (MLEs) of the parameters will be the parameter values that are most likely to have generated our data.\n\n## Example 1\n\n-   Consider a simple coin-flipping example. Let's say we flipped a coin 200 times and observed 103 heads and 97 tails. If the probability of \"success\" (i.e. getting a head) is $p$,\n    1.  Define a function that will calculate the likelihood function for a given value of $p$; then\n\n    2.  Search for the value of $p$ that results in the highest likelihood.\n\n## Example 2\n\nSuppose we have data points representing the weight (in kg) of students in a class.\n\n```{r}\nset.seed(2022)\nWeight=round(rnorm(50,50,10),3)\nprint(Weight)\n```\n\nThis dataset appears to follow a normal distribution. Find the MLEs for the mean and standard deviation for this distribution?\n\n------------------------------------------------------------------------\n\n#### Normal distribution - Maximum Likelihood Estimation\n\n-   The MLE of $\\mu$ is defined as $\\hat{\\mu}_{MLE}=argmax(x_1,...,x_n|\\mu,\\sigma^2)$; where $\\hat{\\mu}_{MLE}$ is the value of $\\mu$ that maximizes the likelihood function.\n\n![](images/paste-CAB44AE1.png){fig-align=\"center\" width=\"4471\"}\n\n-   If we maximise the above likelihood function, we get $\\hat{\\mu}_{MLE}=\\bar{x}.$\n\n-   Since the MLE of $\\mu$ is the sample mean, computing the MLE in R becomes straightforward.\n\n## Interval Estimation\n\n-   Point estimators are often use as sample measures for population parameters.\n\n-   It is also helpful to know how reliable this estimate is, that is, how much sampling uncertainty is associated with it.\n\n-   A useful way to express this uncertainty is to calculate an interval estimate or confidence interval for the population parameter\n\n-   In other words, the confidence interval is of the form \"**point estimate ¬± uncertainty**\"\n\n## \n\n### Confidence Interval for Mean\n\n**Case 1**: When data is normal/ large sample and $\\sigma$ is known.\n\n$$\\bar{x}\\pm z_{\\alpha/2}\\sigma/\\sqrt{n}$$\n\n![](images/paste-828890DC.png)\n\n------------------------------------------------------------------------\n\n**Case 2**: When data is normal/ large samples and $\\sigma$ is unknown.\n\n$$\\bar{x}\\pm t_{n-1,\\alpha/2}\\sigma/\\sqrt{n}$$\n\n![](images/paste-1B9E4230.png)\n\n------------------------------------------------------------------------\n\n**Case 3**: When data is non-normal/ small samples\n\n-   For this, bootstrap approach is used as follows.\n\n![](images/paste-E97242D1.png)\n\n------------------------------------------------------------------------\n\n### CONFIDENCE INTERVALS FOR Difference of Means\n\n**Case 1:** Sampling from two independent normal distributions with known variances.\n\n![](images/paste-EAF7E47A.png)\n\n![](images/paste-2363134F.png)\n\n    library(\"BSDA\")\n    z.test(x,y = NULL,alternative = \"two.sided\",\n    sigma.x = NULL, sigma.y = NULL, conf.level = 0.95)\n\n------------------------------------------------------------------------\n\n**Case 2:** Sampling from two independent normal distributions with unknown variances (small samples).\n\n-   when population variances are equal\n\n![](images/paste-20EC42F5.png)\n\n        t.test(x,y,alternative = \"two.sided\",\n        var.equal=TRUE, conf.level = 0.95)\n\n------------------------------------------------------------------------\n\n-   when population variances are unequal\n\n![](images/paste-AD18975E.png)\n\n![](images/paste-D5AF962F.png)\n\n      t.test(x,y,alternative = \"two.sided\",\n        var.equal=FALSE, conf.level = 0.95)\n\n------------------------------------------------------------------------\n\n### Confidence Interval Chart in R (Independent Means & CIs)\n\n![](https://www.researchgate.net/profile/Sarah-Vanhoutte/publication/294318520/figure/fig16/AS:614068499009558@1523416747796/Graph-depicting-the-95-confidence-interval-of-the-CNV-slope-for-all-electrodes-of.png)\n\n------------------------------------------------------------------------\n\n-   Example\n\n```{r}\n#| echo: true\nset.seed(123456)                 # Create example data\ndata <- data.frame(x = c(\"A\",\"B\",\"C\"),\n                  y = round(runif(3, 10, 20),2),\n                  lower = round(runif(3, 0, 10),2),\n                  upper = round(runif(3, 20, 30),2))\n\nlibrary(ggplot2)\nggplot(data, aes(x, y)) +        # ggplot2 plot with confidence intervals\n  geom_point() +\n  geom_errorbar(aes(ymin = lower, ymax = upper))\n```\n\n------------------------------------------------------------------------\n\n### Confidence Intervals for Proportion\n\n-   **Case 1**: For large sample (Using Normal approximation)\n\n$$ \\hat{p}\\pm Z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n\n![](images/paste-7C863FC6.png)\n\n------------------------------------------------------------------------\n\n**Case 1**: For large sample (Using Binomial Distribution)\n\n-   we can use the following functions from R package *epitools* for this case.\n\n![](images/paste-A89B3710.png)\n\n------------------------------------------------------------------------\n\n**Case 2**: For small sample (Using Binomial Distribution)\n\n-   When sample size is small, confidence interval for population can be calculated using binom.test() function.\n\n![](images/paste-74B0E647.png)\n\n------------------------------------------------------------------------\n\n### Confidence Intervals for Variance\n\n**Case 1**: Under normality assumption\n\n-   User defined function to obtain confidence interval for variance.\n\n<!-- -->\n\n     var.interval = function(data, conf.level = 0.95) {\n     df = length(data) - 1\n     chilower = qchisq((1 - conf.level)/2, df)\n     chiupper = qchisq((1 - conf.level)/2, df, lower.tail = FALSE)\n     v = var(data)\n     c(df * v/chiupper, df * v/chilower)\n     }\n     \n     lizard = c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5, 8.6, 8.8, 8.8, 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8, 11.3, 11.9)\n\n     var.interval(lizard)\n\n------------------------------------------------------------------------\n\n**Case 2**: Under non-normality assumption\n\n-   When no assumption is made about data, a bootstrap method is used to obtain confidence intervals for the population variance.\n\n![](images/paste-41E6DA37.png)\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["../lectures.css"],"output-file":"lecture3.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.0.38","auto-stretch":true,"editor":"visual","sidebar":"lectures","search":false,"title":"DSC 3091- Advanced Statistics Applications I","subtitle":"Point Estimation and Confidence Intervals","author":"Dr Jagath Senarathne","institute":"Department of Statistics and Computer Science","theme":["serif","custom.scss"],"slideNumber":true,"chalkboard":{"theme":"whiteboard"}}}}}