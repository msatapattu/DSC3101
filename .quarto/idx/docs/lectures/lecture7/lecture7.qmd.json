{"title":"DSC 3091- Advanced Statistics Applications I","markdown":{"yaml":{"title":"DSC 3091- Advanced Statistics Applications I","subtitle":"Categorical Data Analysis","format":{"revealjs":{"large":true,"theme":["beige","custom.scss"],"slide-number":true,"chalkboard":{"theme":"whiteboard"}}},"editor":"visual"},"headingText":"Types of Data","containsRefs":false,"markdown":"\n\n\nData is generally divided into two categories:\n\n-   **Quantitative data** represents amounts.\n\n-   **Categorical data** represents groupings.\n\nA variable that contains quantitative data is a **quantitative variable**; a variable that contains categorical data is a **categorical variable**.\n\n# Types of Data\n\n**Quantitative variables**\n\nThe quantitative data represent real amounts that can be added, subtracted, divided, etc. There are two types of quantitative variables:\n\n-   **Discrete** (**integer)**: Counts of individual items or values.\n\n    Examples: Number of students in a class, Number of different tree species in a forest\n\n-   **Continuous** variables: Measurements of continuous or non-finite values.\n\n    Examples: Distance, Volume, Temperature\n\n# **Categorical variables**\n\nThere are three types of categorical variables:\n\n-   **binary (dichotomous)** variables: Two outcomes (Yes/no) Examples: Heads/tails in a coin flip, Gender\n\n-   **nominal** variables: Groups with no rank or order between them.\n\n    Examples: Hair colour, Nationality\n\n-   **ordinal** variables: Groups that are ranked in a specific order. Examples: Rating scale, responses in a survey\n\n# Summarizing Categorical data\n\n-   Probability distributions for categorical data:\n\n    -   Binomial distribution\n\n    -   Multinomial distribution\n\n**Example 1**\n\nLet us consider the `knee` dataset in `catdata` R package\n\nIn a clinical study n=127 patients with sport related injuries have been treated with two different therapies (chosen by random design) with 8 variables. After 3,7 and 10 days of treatment the pain occurring during knee movement was observed.\n\n# Summarizing Categorical data\n\n| Variable | Description                                          |\n|----------|------------------------------------------------------|\n| N        | Patient's number                                     |\n| Th       | Therapy ( placebo = 1, treatment = 2)                |\n| Age      | Age in years                                         |\n| Sex      | Gender (male = 0, female = 1)                        |\n| R1       | Pain before treatment (no pain = 1, severe pain = 5) |\n| R2       | Pain after three days of treatment                   |\n| R3       | Pain after seven days of treatment                   |\n| R4       | Pain after ten days of treatment                     |\n\n------------------------------------------------------------------------\n\n```{r,echo=T}\nlibrary(catdata)\ndata(knee)\nhead(knee)\n```\n\n-   Check the structure of the data\n\n```{r,echo=T}\nstr(knee)\n```\n\n------------------------------------------------------------------------\n\n-   Convert into factor variables\n\n```{r,echo=T}\nknee$Th <- as.factor(knee$Th)\nknee$Sex <- as.factor(knee$Sex)\nstr(knee)\n```\n\n------------------------------------------------------------------------\n\n-   Changing factor levels\n\n```{r,echo=T}\nlevels(knee$Th) <- c(\"Placebo\",\"Treatment\") \nlevels(knee$Sex) <-c(\"Male\",\"Female\")\nhead(knee)\n```\n\n# Categorical data visualization\n\nThe distribution of a single categorical variable is typically plotted with a **bar chart**, a **pie chart**, or a **tree map**. We can draw bar charts for counts or percentages, and each bar represents a categorical variable.\n\nUse a pie charts if you want to compare each category with the whole, and the number of categories is small.\n\nAn alternative to a pie chart is a tree map. Unlike pie charts, it can handle categorical variables that have many levels.\n\n# Categorical data visualization\n\nWhen plotting the relationship between two categorical variables, **stacked**, **grouped**, or **segmented bar charts** are typically used. A less common approach is the **mosaic chart**.\n\nRefer here: https://rkabacoff.github.io/datavis/Bivariate.html\n\n# Group Bar Chart\n\n```{r,echo=T}\nlibrary(ggplot2)\nggplot(knee, aes(x = R2, fill = Th)) + geom_bar(position = \"dodge\") +\n  labs(x = \"Pain after trteatment\", \n       y = \"Number of patients\", \n       fill = \"Treatment\")\n```\n\n# Stack Bar Chart\n\n```{r echo=T}\nlibrary(ggplot2)\nggplot(knee, \n       aes(x = R2, \n           fill = Th)) + \n  geom_bar(position = \"stack\")+\n  scale_fill_discrete(labels = c(\"placebo\", \"treatment\"))\n```\n\n# Mosaic plots\n\n```{r echo=T}\ntbl <- xtabs(~Th +Sex+R1, knee)\nftable(tbl)\nlibrary(vcd)\nmosaic(tbl, main = \"Pain before treatment\", shade = TRUE, legend = TRUE)\n```\n\n# Creating tabulated summaries\n\n```{r,echo=T}\nT1=table(knee$Th)#Selecting only the Th variable\nT1\nprop.table(T1)\nT2=table(knee$Th,knee$Sex)#Selecting both Th and Sex variables\nT2\nprop.table(T2)\n```\n\n------------------------------------------------------------------------\n\n-   Using `CrossTable` function in `gmodels` package\n\n```{r,echo=T}\nlibrary(gmodels)\nCrossTable(table(knee$Th,knee$Sex))\n```\n\n# Chi-square goodness of fit test\n\n-   A statistical hypothesis test used to determine whether a variable is likely to come from a specified distribution or not.\n\n-   In Knee injuries dataset, let's check whether the patients were randomly allocated to the treatment and placebo groups.\n\n    -   Null hypothesis: $P_{trt}=P_{plc}=0.5$\n\n------------------------------------------------------------------------\n\n```{r,echo=T}\nprobabilities <- c(Treatment = .5, Placebo = .5) \nprobabilities\nlibrary(lsr)\ngoodnessOfFitTest(x=knee$Th) # No need to input probabilities if they are equal\n```\n\n# Chi-square test of Independence\n\n-   A hypothesis test used to determine whether two categorical or nominal variables are likely to be related or not.\n\n-   In Knee injuries dataset, let's check whether the variables Th and R2 are independent or not.\n\n-   First, we convert R2 to a factor variable.\n\n```{r echo=T}\nknee$R1=as.factor(knee$R1)\nknee$R2=as.factor(knee$R2)\n```\n\n# Chi-square test of Independence\n\n```{r,echo=T}\nlibrary(lsr)\nassociationTest( formula = ~Th+R2, data = knee )\n```\n\n## Another way to do chi-square tests in R\n\n-   goodness of fit\n\n```{r,echo=T}\nchisq.test(x=table(knee$Th))\n```\n\n-   Independence\n\n```{r,echo=T,eval=F}\nT3=table(knee$Th,knee$R2)\nchisq.test(T3)\n```\n\n# Assumptions of chi-square test\n\n-   Expected frequencies are sufficiently large.\n\n    ::: callout-tip\n    ## If this assumption is violated\n\n    If your expected cell counts are too small, check out the Fisher exact test.\n    :::\n\n-   Observations are independent.\n\n    ::: callout-tip\n    ## If observations are not independent\n\n    Use the McNemar test or the Cochran test.\n    :::\n\n# Fisher exact test\n\n-   The Fisher exact test works somewhat differently to the chi-square test (or in fact any of the other hypothesis tests)\n\n-   As can be seen it does not calculate a test statistic.\n\n```{r, echo=T}\nT3=table(knee$Th,knee$R2)\nfisher.test(T3)\n```\n\n# McNemar test\n\n-   Suppose we want to check whether the two variables R2 and R3 are independent or not.\n\n-   Here, both variables measure the pain of the same set of patients after the treatment.\n\n-   Therefore, these observations can be correlated.\n\n```{r, echo=T}\nR2.merge=factor(ifelse(knee$R2==1 | knee$R2==2,1,2))\nR3.merge=ifelse(knee$R3==1 | knee$R3==2,1,2)\nT4=table(R2.merge,R3.merge)\nmcnemar.test(T4)\n```\n\n# Odds Ratio and 95% CI\n\n```{r, echo=T}\nlibrary(vcd) # install the package first\nT5 <-table(knee$R4,knee$Th)\nodds.2cb <- oddsratio(T5,log=F) # computes the odds ratio\nsummary(odds.2cb) # summary displays the odds ratio\n```\n\n```{r,echo=T}\nconfint(odds.2cb) # displays the confidence intervals\n```\n\n------------------------------------------------------------------------\n\n-   Plot the odds ratio and their respective confidence intervals.\n\n```{r,echo=T}\nplot(odds.2cb, main = \"Relative Odds of Placebo\", xlab = \"Pain after treatment\", ylab = \"Odds Ratio, 95% CI\")\n```\n\n# Kendall rank correlation\n\n-   Kendall rank correlation is used to test the similarities in the ordering of data.\n\n-   A better alternative to Spearman correlation (non-parametric) when your sample size is small and has many tied ranks.\n\n-   Example: Customer satisfaction (e.g. Very Satisfied, Somewhat Satisfied, Neutral.) and delivery time (\\< 30 Minutes, 30 minutes - 1 Hour, \\>2 Hours)\n\n------------------------------------------------------------------------\n\n```{r,echo=T}\nres<-cor.test(knee$R3,knee$R4, method=\"kendall\")\nres\n```\n\n# Some Useful Links ...\n\n-   <https://learningstatisticswithr.com/book/>\n\n-   <https://www.r-bloggers.com/2022/01/handling-categorical-data-in-r-part-1/>\n\n-   <https://www.youtube.com/watch?v=uLcd6tRTUEY>\n\n-   <https://towardsdatascience.com/kendall-rank-correlation-explained-dee01d99c535>\n"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","css":["../lectures.css"],"output-file":"lecture7.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.0.38","auto-stretch":true,"editor":"visual","sidebar":"lectures","search":false,"title":"DSC 3091- Advanced Statistics Applications I","subtitle":"Categorical Data Analysis","large":true,"theme":["beige","custom.scss"],"slideNumber":true,"chalkboard":{"theme":"whiteboard"}}}}}